# Promptfoo Configuration - 100 Real PRs
#
# Run: npx promptfoo eval -c promptfoo-100.yaml
# View: npx promptfoo view

description: "AI Detection Prompt Evaluation (v5) - 100 Real PRs"

providers:
  - id: groq:llama-3.3-70b-versatile
    config:
      temperature: 0
      max_tokens: 500
      response_format:
        type: json_object

prompts:
  - id: v5
    raw: |
      [
        {"role": "system", "content": "{{system_prompt}}"},
        {"role": "user", "content": "Analyze this pull request:\n\nTitle: {{pr_title}}\nLines: +{{additions}}/-{{deletions}}\n\nDescription:\n{{pr_body}}"}
      ]

# Default variables
defaultTest:
  vars:
    pr_body: ""
    pr_title: ""
    additions: 0
    deletions: 0
    system_prompt: file://prompts/v5-system.txt
  assert:
    - type: is-json
    - type: javascript
      value: |
        const r = JSON.parse(output);
        return typeof r.ai?.is_assisted === 'boolean' &&
               Array.isArray(r.ai?.tools) &&
               typeof r.ai?.confidence === 'number';

# Load 100 real PRs from exported JSON (array format)
tests: file://test-cases-100-array.json

# Output configuration
outputPath: ./results/promptfoo-100-results.json

# Evaluation settings
evaluateOptions:
  maxConcurrency: 5
  showProgressBar: true
